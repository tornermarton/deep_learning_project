{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl-project-loremimpsum.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tornermarton/deep_learning_project/blob/master/dl_project_loremimpsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X6CGXvShrkRg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Authorship identification using deep learning\n",
        "**Füleki Fábián,\tJani Balázs Gábor,\tTorner Márton**  \n",
        "*Project work for BME Deep Learning course (VITMAV45),  \n",
        "Team: LoremIpsum*\n",
        "\n",
        "\n",
        "**Milestone I**\n",
        "\n",
        "**Dataset:**  \n",
        "Our primary dataset is the Reuters_50_50 (C50), which is a subset of Reuters Corpus Volume I(RCVI). The RCV1 is archive of categorized newswire stories, made public for research purposes by Reuters, Ltd. The C50 collection consist of 50 texts for each of the 50 top author, for training and separately the same amount for testing purpose (5000 texts in total). This dataset has been previous used by previous studies of authorship recognition and can be found here: https://archive.ics.uci.edu/ml/machine-learning-databases/00217/C50.zip\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "lfL_i-ZRPjR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepaing Dataset and visualizing the result\n",
        "\n",
        "**Milestone I**"
      ]
    },
    {
      "metadata": {
        "id": "3sKUlzl7FC9G",
        "colab_type": "code",
        "outputId": "3457de32-9cc4-4e7a-cf80-9df6f4fd2b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "# Clean storage for new files\n",
        "!rm -r C50*\n",
        "\n",
        "# Download of the Reuter_50_50 (C50) dataset\n",
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00217/C50.zip\"\n",
        "!unzip -q C50.zip\n",
        "\n",
        "# Download contains 2 directories split, merge them (we will do custom splitting)\n",
        "!mkdir C50\n",
        "!mv C50train/* C50/\n",
        "!rsync -a C50test/ C50/\n",
        "\n",
        "# Clean files we don't need\n",
        "!rm C50.zip\n",
        "!rm -r C50train\n",
        "!rm -r C50test"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'C50*': No such file or directory\n",
            "--2018-10-31 17:01:53--  https://archive.ics.uci.edu/ml/machine-learning-databases/00217/C50.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8194031 (7.8M) [application/zip]\n",
            "Saving to: ‘C50.zip’\n",
            "\n",
            "C50.zip             100%[===================>]   7.81M  2.15MB/s    in 3.6s    \n",
            "\n",
            "2018-10-31 17:01:57 (2.15 MB/s) - ‘C50.zip’ saved [8194031/8194031]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SecQn64b5N9m",
        "colab_type": "code",
        "outputId": "b700c94e-a89c-4d4d-dff0-bfca634c44af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "# Download and install the largest language pack for SpaCy\n",
        "# It contains 1 000 000 word vectors (so only very rare words can't be processed)\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz (852.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 852.3MB 46.6MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "  Running setup.py install for en-core-web-lg ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-lg-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2NhHEv3P5QHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get required resources\n",
        "import spacy\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from nltk import tokenize\n",
        "from keras.utils import np_utils\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Alt2PuV9HeL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "pd.set_option(\"max_columns\", None)\n",
        "nlp = spacy.load('en_core_web_lg', disable=['ner','parser'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvDWMcmL7gJq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_sentences_from_file(author, author_id, filename):\n",
        "  data = \"\"\n",
        "  sentences = []\n",
        "\n",
        "  # parse file\n",
        "  with open(\"C50/\"+author+\"/\"+filename, 'r') as file:\n",
        "      data=file.read()\n",
        "      \n",
        "  # split article into sentences\n",
        "  for sentence in tokenize.sent_tokenize(data):\n",
        "    sentences.append([author_id, sentence])\n",
        "  \n",
        "  return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uouv0rk5Q3y8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# authors must be represented as numbers so we create\n",
        "# a list and the indexes are the repesentations - easy translation\n",
        "\n",
        "# array which contains the authors' names\n",
        "authors = []\n",
        "\n",
        "# translate back id - clear result\n",
        "def match_author(id):\n",
        "  return authors[id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SujEA2XF_alz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_raw_sentences():\n",
        "  raw_sentences = []\n",
        "  authors = []\n",
        "  # read every file (articles) in the previously given root directory, the subdirectories are the authors' names\n",
        "  for root, dirs, files in os.walk(\"C50\"):\n",
        "    for dir in dirs:\n",
        "      authors.append(str(dir))\n",
        "      for file in os.listdir(\"C50/\"+dir):\n",
        "        raw_sentences.extend(read_sentences_from_file(dir, len(authors)-1, file))\n",
        "\n",
        "  return raw_sentences, authors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HJ6s1lWl248E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sentence parsing**\n",
        "\n",
        "We parse all the sentences with SpaCy in the followig way:\n",
        "\n",
        "1. Tokenize the sentence (split into words - in SpaCy the punctuation characters also count as words, but we remove them later, because they do not contain needed information)\n",
        "\n",
        "2. Get the vector form of each word, if it is not part of the largest collection (very rare words) we leave them out, because we can only use vectors for the inputs.\n",
        "\n",
        "3. Detect for each word which part of the sentence it is (part-of-speech tags - syntactic information)\n"
      ]
    },
    {
      "metadata": {
        "id": "NewjoP-KzrbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_raw_sentences(sentences, verbose=False):\n",
        "  # just for writing out fancy things\n",
        "  if verbose:\n",
        "    start_time = time.time()\n",
        "    s = \"\"\n",
        "    \n",
        "  parsed_sentences = np.empty([len(sentences)], dtype=[('author', object, 1), ('original', object, 1), ('parsed', object, 1)])\n",
        "  \n",
        "  # parse every sentence (word splitting -> tokens, determine part-of-speech tags for every word)\n",
        "  end = len(sentences)\n",
        "  for i in range(0, end):\n",
        "    author = sentences[i][0]\n",
        "    raw_sentence = sentences[i][1]\n",
        "    parsed = np.array([], dtype=[('text', object, 1), ('vector', object, 1), ('pos_str', object, 1), ('pos_num', object, 1)])\n",
        "    \n",
        "    doc = nlp(raw_sentence)\n",
        "   \n",
        "    for token in doc:\n",
        "      # filter out stop words (not relevant/useful)\n",
        "      # 96 = punctuation char (->SpaCy documentation)\n",
        "      # if a word does not have vector form filter it out (very, very rare case)\n",
        "      if not token.is_stop and not token.pos == 96 and token.has_vector:\n",
        "        parsed = np.append(parsed, np.array((token.text, token.vector, token.pos_, token.pos), dtype=[('text', object, 1), ('vector', object, 1), ('pos_str', object, 1), ('pos_num', object, 1)]))\n",
        "    \n",
        "      parsed_sentences[i] = (author, raw_sentence, parsed)\n",
        "    \n",
        "    # just for writing out fancy things\n",
        "    if verbose and (i+1)%1000 == 0 or i == end-1:\n",
        "      if i != 0: \n",
        "        s =  str(i+1)+ \"/\" + str(end) +\" sentences parsed in \" +str(round(time.time() - start_time))+ \" seconds.\"\n",
        "      \n",
        "      j = int((i+1)/end*50)\n",
        "    \n",
        "      sys.stdout.write('\\r'+ \"Processing. [\" + \"=\"*j + \">\" + \" \"*(50-j) + \"] \" + s )\n",
        "  \n",
        "  if verbose:\n",
        "    print('\\n' + \"Sentences successfully parsed.\")\n",
        "  \n",
        "  return parsed_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "swUKZX2X9ZKq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_avg_sentence_len(sentences):\n",
        "  sum = 0\n",
        "  count = 0\n",
        "  for sentence in sentences['parsed']:\n",
        "    if type(sentence).__name__ == \"NoneType\":\n",
        "        print(sentence)\n",
        "        print(count)\n",
        "    sum += len(sentence)\n",
        "    count += 1\n",
        "  \n",
        "  return sum/count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6suItkDJ29xG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Equalization of the sentences in the dataset**\n",
        "\n",
        "We plan to use sentence based identification so out system needs sentences which have equal lengths (word count), but obviously the articles are not written in this way, so we have to make the equalization. We calculate the average word count of the sentences in the dataset and then we transform all of them to contain the same number of words (we round up the average to keep more sentences in the full form).\n",
        "\n",
        "Too short sentences are extended with wildcard (magic) words which will be filtered out in a way in the learning process.\n",
        "\n",
        "Too long sentences are simply cut to shape."
      ]
    },
    {
      "metadata": {
        "id": "MN1hSThT8s3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def equalize_sentence_len(sentences):\n",
        "  # calculate the average sentence length and round it up (we try to keep most of the sentences)\n",
        "  avg = math.ceil(count_avg_sentence_len(sentences))\n",
        "  \n",
        "  equalized_sentences = np.empty([len(sentences)], dtype=[('author', object, 1), ('original', object, 1), ('parsed', object, 1)])\n",
        "  \n",
        "  n_sentences = 0\n",
        "  \n",
        "  # process \n",
        "  for i in range(0, len(sentences)):\n",
        "    sentence = sentences[i]\n",
        "    \n",
        "    sys.stdout.write('\\r'+ str(i) +\" sentences equalized.\")\n",
        "    \n",
        "    if len(sentence['parsed']) > 7:\n",
        "      n_sentences += 1\n",
        "      \n",
        "      # 'magic words' : text = Xxxxxx ; vector=nullvector ; pos_tag='' ; pos_tag number form : 0\n",
        "      # insert magic word into random positions for every sentence, which is too short (shorter, than average)\n",
        "      while len(sentence['parsed']) < avg:\n",
        "        idx = np.random.randint(len(sentence['parsed']))\n",
        "        sentence['parsed'] = np.insert(sentence['parsed'], idx, np.array((\"Xxxxxx\", np.zeros(300), \"\", 0), dtype=[('text', object, 1), ('vector', object, 1), ('pos_str', object, 1), ('pos_num', object, 1)]), axis=0)\n",
        "\n",
        "      # if sentence is too long cut it\n",
        "      if len(sentence['parsed']) > avg:\n",
        "        sentence['parsed'] = sentence['parsed'][0:avg]\n",
        "        \n",
        "      equalized_sentences[n_sentences-1] = sentence\n",
        "  \n",
        "  print('\\n')\n",
        "  return equalized_sentences[:n_sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_gAUg9hFycB",
        "colab_type": "code",
        "outputId": "22129a30-72a1-4c07-bf9f-996c950f479d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "raw_sentences, authors = load_raw_sentences()\n",
        "print(\"Total number of the loaded sentences: \" + str(len(raw_sentences)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of the loaded sentences: 108473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eFlD8nkey7bA",
        "colab_type": "code",
        "outputId": "8dcc2d87-9358-407a-b787-1e05a10ff270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#load only the first 10000 sentences for demonstration (parsing 100000+ sentences would be 10+ minutes) 96k - 97k\n",
        "dataset = parse_raw_sentences(raw_sentences[:60000], True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing. [==================================================>] 60000/60000 sentences parsed in 429 seconds.\n",
            "Sentences successfully parsed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DiFr9OpPXs0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_safe = dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8sAM7X8_fPs",
        "colab_type": "code",
        "outputId": "59ec8ce3-5a3c-497d-842c-32783fa56918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "avg_before = count_avg_sentence_len(dataset)\n",
        "print(\"The average sentence length before the equalization: \" + str(avg_before) + '\\n')\n",
        "\n",
        "# equalize the length of the sentences (we need the number of words to be equal)\n",
        "dataset = equalize_sentence_len(dataset)\n",
        "\n",
        "avg_after = count_avg_sentence_len(dataset)\n",
        "print(\"And after: \" + str(avg_after))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average sentence length before the equalization: 24.027566666666665\n",
            "\n",
            "59999 sentences equalized.\n",
            "\n",
            "And after: 25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5IMsfD36Gpw",
        "colab_type": "code",
        "outputId": "f7f44328-caa7-4799-d4da-f8f71e519336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"One sample sentence:\\n\")\n",
        "print(\"Author: \" + str(authors[dataset[\"author\"][0]]) )\n",
        "print(\"Sentence: \" + dataset[\"original\"][0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One sample sentence:\n",
            "\n",
            "Author: PierreTran\n",
            "Sentence: The restructuring of France's defence sector and the key role of state-owned Aerospatiale in the process are complicating moves by the European Airbus consortium to become a limited liability company, analysts say.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AenGC9te0ub4",
        "colab_type": "code",
        "outputId": "40a13261-c0b1-4eb8-9baf-e66b68178e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"The parsed form of the above sentence:\")\n",
        "df = pd.DataFrame(data=dataset[\"parsed\"][0])\n",
        "df.T"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parsed form of the above sentence:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>The</td>\n",
              "      <td>restructuring</td>\n",
              "      <td>of</td>\n",
              "      <td>France</td>\n",
              "      <td>'s</td>\n",
              "      <td>defence</td>\n",
              "      <td>sector</td>\n",
              "      <td>and</td>\n",
              "      <td>the</td>\n",
              "      <td>key</td>\n",
              "      <td>role</td>\n",
              "      <td>of</td>\n",
              "      <td>state</td>\n",
              "      <td>owned</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>process</td>\n",
              "      <td>are</td>\n",
              "      <td>complicating</td>\n",
              "      <td>moves</td>\n",
              "      <td>by</td>\n",
              "      <td>the</td>\n",
              "      <td>European</td>\n",
              "      <td>Airbus</td>\n",
              "      <td>consortium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vector</th>\n",
              "      <td>[0.27204, -0.06203, -0.1884, 0.023225, -0.0181...</td>\n",
              "      <td>[-0.014888, 0.46349, 0.17002, 0.071424, -0.324...</td>\n",
              "      <td>[0.060216, 0.21799, -0.04249, -0.38618, -0.153...</td>\n",
              "      <td>[-0.16306, 0.45292, -0.14638, -0.64332, 0.7901...</td>\n",
              "      <td>[-0.06858, 0.4647, 0.13214, 0.18599, -0.037015...</td>\n",
              "      <td>[-0.19166, 0.029525, 0.29589, -0.0074387, -0.0...</td>\n",
              "      <td>[-0.22519, -0.0038701, 0.70118, -0.3173, 0.310...</td>\n",
              "      <td>[-0.18567, 0.066008, -0.25209, -0.11725, 0.265...</td>\n",
              "      <td>[0.27204, -0.06203, -0.1884, 0.023225, -0.0181...</td>\n",
              "      <td>[0.33578, 0.30902, 0.12098, 0.28478, 0.1912, -...</td>\n",
              "      <td>[0.061541, 0.018384, -0.14051, 0.38658, -0.366...</td>\n",
              "      <td>[0.060216, 0.21799, -0.04249, -0.38618, -0.153...</td>\n",
              "      <td>[0.17925, 0.13343, 0.50349, -0.16948, 0.084366...</td>\n",
              "      <td>[0.22627, -0.49824, -0.1902, -0.79974, 0.22603...</td>\n",
              "      <td>[0.089187, 0.25792, 0.26282, -0.029365, 0.4718...</td>\n",
              "      <td>[0.27204, -0.06203, -0.1884, 0.023225, -0.0181...</td>\n",
              "      <td>[-0.4198, 0.35442, -0.046745, 0.029734, -0.282...</td>\n",
              "      <td>[-0.19859, -0.062818, -0.36614, -0.41786, 0.20...</td>\n",
              "      <td>[-0.19487, 0.26783, 0.13248, 0.11664, -0.59535...</td>\n",
              "      <td>[0.04274, 0.017064, -0.16807, -0.0042404, 0.63...</td>\n",
              "      <td>[-0.15552, -0.33723, -0.097191, -0.21617, -0.3...</td>\n",
              "      <td>[0.27204, -0.06203, -0.1884, 0.023225, -0.0181...</td>\n",
              "      <td>[-0.54638, -0.15723, 0.13512, -0.086275, 0.521...</td>\n",
              "      <td>[0.51443, 0.033396, 0.42992, -0.3703, 0.034822...</td>\n",
              "      <td>[-0.11816, -0.86385, 0.83966, -0.33966, 0.0389...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos_str</th>\n",
              "      <td>DET</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PART</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>DET</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>VERB</td>\n",
              "      <td>ADP</td>\n",
              "      <td>DET</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>DET</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos_num</th>\n",
              "      <td>89</td>\n",
              "      <td>91</td>\n",
              "      <td>84</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "      <td>91</td>\n",
              "      <td>91</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>83</td>\n",
              "      <td>91</td>\n",
              "      <td>84</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>84</td>\n",
              "      <td>89</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>91</td>\n",
              "      <td>84</td>\n",
              "      <td>89</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        0   \\\n",
              "text                                                   The   \n",
              "vector   [0.27204, -0.06203, -0.1884, 0.023225, -0.0181...   \n",
              "pos_str                                                DET   \n",
              "pos_num                                                 89   \n",
              "\n",
              "                                                        1   \\\n",
              "text                                         restructuring   \n",
              "vector   [-0.014888, 0.46349, 0.17002, 0.071424, -0.324...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        2   \\\n",
              "text                                                    of   \n",
              "vector   [0.060216, 0.21799, -0.04249, -0.38618, -0.153...   \n",
              "pos_str                                                ADP   \n",
              "pos_num                                                 84   \n",
              "\n",
              "                                                        3   \\\n",
              "text                                                France   \n",
              "vector   [-0.16306, 0.45292, -0.14638, -0.64332, 0.7901...   \n",
              "pos_str                                              PROPN   \n",
              "pos_num                                                 95   \n",
              "\n",
              "                                                        4   \\\n",
              "text                                                    's   \n",
              "vector   [-0.06858, 0.4647, 0.13214, 0.18599, -0.037015...   \n",
              "pos_str                                               PART   \n",
              "pos_num                                                 93   \n",
              "\n",
              "                                                        5   \\\n",
              "text                                               defence   \n",
              "vector   [-0.19166, 0.029525, 0.29589, -0.0074387, -0.0...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        6   \\\n",
              "text                                                sector   \n",
              "vector   [-0.22519, -0.0038701, 0.70118, -0.3173, 0.310...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        7   \\\n",
              "text                                                   and   \n",
              "vector   [-0.18567, 0.066008, -0.25209, -0.11725, 0.265...   \n",
              "pos_str                                              CCONJ   \n",
              "pos_num                                                 88   \n",
              "\n",
              "                                                        8   \\\n",
              "text                                                   the   \n",
              "vector   [0.27204, -0.06203, -0.1884, 0.023225, -0.0181...   \n",
              "pos_str                                                DET   \n",
              "pos_num                                                 89   \n",
              "\n",
              "                                                        9   \\\n",
              "text                                                   key   \n",
              "vector   [0.33578, 0.30902, 0.12098, 0.28478, 0.1912, -...   \n",
              "pos_str                                                ADJ   \n",
              "pos_num                                                 83   \n",
              "\n",
              "                                                        10  \\\n",
              "text                                                  role   \n",
              "vector   [0.061541, 0.018384, -0.14051, 0.38658, -0.366...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        11  \\\n",
              "text                                                    of   \n",
              "vector   [0.060216, 0.21799, -0.04249, -0.38618, -0.153...   \n",
              "pos_str                                                ADP   \n",
              "pos_num                                                 84   \n",
              "\n",
              "                                                        12  \\\n",
              "text                                                 state   \n",
              "vector   [0.17925, 0.13343, 0.50349, -0.16948, 0.084366...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        13  \\\n",
              "text                                                 owned   \n",
              "vector   [0.22627, -0.49824, -0.1902, -0.79974, 0.22603...   \n",
              "pos_str                                               VERB   \n",
              "pos_num                                                 99   \n",
              "\n",
              "                                                        14  \\\n",
              "text                                                    in   \n",
              "vector   [0.089187, 0.25792, 0.26282, -0.029365, 0.4718...   \n",
              "pos_str                                                ADP   \n",
              "pos_num                                                 84   \n",
              "\n",
              "                                                        15  \\\n",
              "text                                                   the   \n",
              "vector   [0.27204, -0.06203, -0.1884, 0.023225, -0.0181...   \n",
              "pos_str                                                DET   \n",
              "pos_num                                                 89   \n",
              "\n",
              "                                                        16  \\\n",
              "text                                               process   \n",
              "vector   [-0.4198, 0.35442, -0.046745, 0.029734, -0.282...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        17  \\\n",
              "text                                                   are   \n",
              "vector   [-0.19859, -0.062818, -0.36614, -0.41786, 0.20...   \n",
              "pos_str                                               VERB   \n",
              "pos_num                                                 99   \n",
              "\n",
              "                                                        18  \\\n",
              "text                                          complicating   \n",
              "vector   [-0.19487, 0.26783, 0.13248, 0.11664, -0.59535...   \n",
              "pos_str                                               VERB   \n",
              "pos_num                                                 99   \n",
              "\n",
              "                                                        19  \\\n",
              "text                                                 moves   \n",
              "vector   [0.04274, 0.017064, -0.16807, -0.0042404, 0.63...   \n",
              "pos_str                                               NOUN   \n",
              "pos_num                                                 91   \n",
              "\n",
              "                                                        20  \\\n",
              "text                                                    by   \n",
              "vector   [-0.15552, -0.33723, -0.097191, -0.21617, -0.3...   \n",
              "pos_str                                                ADP   \n",
              "pos_num                                                 84   \n",
              "\n",
              "                                                        21  \\\n",
              "text                                                   the   \n",
              "vector   [0.27204, -0.06203, -0.1884, 0.023225, -0.0181...   \n",
              "pos_str                                                DET   \n",
              "pos_num                                                 89   \n",
              "\n",
              "                                                        22  \\\n",
              "text                                              European   \n",
              "vector   [-0.54638, -0.15723, 0.13512, -0.086275, 0.521...   \n",
              "pos_str                                              PROPN   \n",
              "pos_num                                                 95   \n",
              "\n",
              "                                                        23  \\\n",
              "text                                                Airbus   \n",
              "vector   [0.51443, 0.033396, 0.42992, -0.3703, 0.034822...   \n",
              "pos_str                                              PROPN   \n",
              "pos_num                                                 95   \n",
              "\n",
              "                                                        24  \n",
              "text                                            consortium  \n",
              "vector   [-0.11816, -0.86385, 0.83966, -0.33966, 0.0389...  \n",
              "pos_str                                               NOUN  \n",
              "pos_num                                                 91  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "JS56XviL7pLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preparing dataset for the NeuralNetwork**"
      ]
    },
    {
      "metadata": {
        "id": "q3UASMRu7pzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_for_nn(dataset):\n",
        "  # sentence_shape: (n_words_per_sentence, word_repr_vector_size) - word_repr_vector_size is the vector representation of the parsed word (300) + last value is the part-of-speech tag (1) => 301 \n",
        "  # input_shape: (n_sentences, n_words_per_sentence, word_repr_vector_size)\n",
        "  \n",
        "  n_sentences           = len(dataset)\n",
        "  n_words_per_sentence  = len(dataset[0][\"parsed\"][\"vector\"])\n",
        "  word_repr_vector_size = len(dataset[0][\"parsed\"][\"vector\"][0])+1\n",
        "  \n",
        "  sentence_shape = (n_words_per_sentence , word_repr_vector_size)\n",
        "  \n",
        "  reworked = np.empty([n_sentences], dtype=[('input', np.float32, sentence_shape), ('output', np.float32, 1)])\n",
        "  \n",
        "  for row in range(0, n_sentences):\n",
        "    reworked[\"output\"][row] = dataset[row][\"author\"]\n",
        "    \n",
        "    for i in range(0, n_words_per_sentence):\n",
        "        reworked[\"input\"][row][i] = np.append(dataset[row][\"parsed\"][\"vector\"][i], dataset[row][\"parsed\"][\"pos_num\"][i]/100)\n",
        "  \n",
        "  return reworked"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FJLraVmdtpg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reworked_dataset = prepare_for_nn(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36_RfV2j63BB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Export the generated dataset to Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "L5x0-HBoOefA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b50976b0-96e0-4346-fe14-eae01cb25eed"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTq37mls8lll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#because of high memory usage, we save the dataset in two parts\n",
        "import pickle\n",
        "with open(\"/content/gdrive/My Drive/loremipsum/reworked_dataset.serialized.part1\", 'wb') as output:\n",
        "   pickle.dump(reworked_dataset[:50000], output, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6TsRa2l8m1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/loremipsum/reworked_dataset.serialized.part2\", 'wb') as output:\n",
        "    pickle.dump(reworked_dataset[50000:], output, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQzTZY6r8nfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/loremipsum/authors.serialized\", 'wb') as output:\n",
        "    pickle.dump(authors, output, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ZcExmUM7KNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Import the generated dataset from Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "WzDAByH18oa1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import\n",
        "import pickle\n",
        "with open('/content/gdrive/My Drive/loremipsum/reworked_dataset.serialized.part1', 'rb') as input:\n",
        "    part1 = pickle.load(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TecKEu_98pHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/loremipsum/reworked_dataset.serialized.part2', 'rb') as input:\n",
        "    part2 = pickle.load(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVsVabeo8qd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reworked_dataset = np.concatenate((part1, part2), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiSdzBf-8sz7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/loremipsum/authors.serialized', 'rb') as input:\n",
        "    authors = pickle.load(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btfOk9cX7eXk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Splitting the dataset"
      ]
    },
    {
      "metadata": {
        "id": "hK_-uEO42DOr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_samples = len(reworked_dataset)\n",
        "valid_split = 0.2\n",
        "test_split = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sy6uIQQ21FVA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shuffle the dataset\n",
        "np.random.shuffle(reworked_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBLXG1TIQRxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train-valid-test split\n",
        "#input\n",
        "X_train = reworked_dataset['input'][0:int(nb_samples*(1-valid_split-test_split))]\n",
        "X_valid = reworked_dataset['input'][int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
        "X_test  = reworked_dataset['input'][int(nb_samples*(1-test_split)):]\n",
        "\n",
        "#output\n",
        "Y_train = reworked_dataset['output'][0:int(nb_samples*(1-valid_split-test_split))]\n",
        "Y_valid = reworked_dataset['output'][int(nb_samples*(1-valid_split-test_split)):int(nb_samples*(1-test_split))]\n",
        "Y_test  = reworked_dataset['output'][int(nb_samples*(1-test_split)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvyOE1FzUsHi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "Y_train = np_utils.to_categorical(Y_train, len(authors))\n",
        "Y_valid = np_utils.to_categorical(Y_valid, len(authors))\n",
        "Y_test = np_utils.to_categorical(Y_test, len(authors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LkUePrgoP9h3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "\n",
        "**Milestone II**"
      ]
    },
    {
      "metadata": {
        "id": "G0Dy-nKEmiiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM, Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xS0BgN26kMHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(network_history):\n",
        "    \n",
        "    #set pltting attributes\n",
        "    #loss-epochs\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(network_history.history['loss'])\n",
        "    plt.plot(network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    #accuracy-epochs\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(network_history.history['acc'])\n",
        "    plt.plot(network_history.history['val_acc'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LqAdI7RgJHLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#setup early stopping\n",
        "es = EarlyStopping(patience=5, verbose=1, min_delta=0.005)\n",
        "\n",
        "#we are going to keep only the best model\n",
        "mcp = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#adding a 1D convolutional layers speeds up learning, but lowers the accuracy\n",
        "# model.add(Conv1D(input_shape=X_train[0].shape, filters=301, kernel_size=4, padding='same', activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "#we are adding an lstm layer with a decent dropout\n",
        "model.add(LSTM(1000, dropout=0.4, recurrent_dropout=0.4, return_sequences=False, input_shape=X_train[0].shape))\n",
        "\n",
        "model.add(Dense(len(authors), activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['mae','acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3ayg_gEonBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1818
        },
        "outputId": "2c4f6c5c-66f3-4ffb-9437-d7a97e7ebef5"
      },
      "cell_type": "code",
      "source": [
        "# set parameters and start learning\n",
        "history = model.fit(X_train, Y_train, \n",
        "          batch_size=1024, \n",
        "          epochs=30, # early stopping detects the end\n",
        "          verbose=1, \n",
        "          validation_data=(X_valid, Y_valid), \n",
        "          shuffle=True,\n",
        "          callbacks=[mcp, es]\n",
        "         )\n",
        "\n",
        "# load back best model (early stopping + model checkpoint)\n",
        "model = load_model('weights.hdf5')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 72049 samples, validate on 20586 samples\n",
            "Epoch 1/30\n",
            "72049/72049 [==============================] - 50s 700us/step - loss: 3.2009 - mean_absolute_error: 0.0369 - acc: 0.1564 - val_loss: 2.5487 - val_mean_absolute_error: 0.0337 - val_acc: 0.2887\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.54870, saving model to weights.hdf5\n",
            "Epoch 2/30\n",
            "72049/72049 [==============================] - 41s 572us/step - loss: 2.5836 - mean_absolute_error: 0.0334 - acc: 0.2849 - val_loss: 2.2518 - val_mean_absolute_error: 0.0310 - val_acc: 0.3678\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.54870 to 2.25183, saving model to weights.hdf5\n",
            "Epoch 3/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 2.3094 - mean_absolute_error: 0.0311 - acc: 0.3528 - val_loss: 2.0863 - val_mean_absolute_error: 0.0294 - val_acc: 0.4091\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.25183 to 2.08633, saving model to weights.hdf5\n",
            "Epoch 4/30\n",
            "72049/72049 [==============================] - 41s 568us/step - loss: 2.1372 - mean_absolute_error: 0.0295 - acc: 0.3964 - val_loss: 1.9654 - val_mean_absolute_error: 0.0277 - val_acc: 0.4384\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.08633 to 1.96541, saving model to weights.hdf5\n",
            "Epoch 5/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 2.0085 - mean_absolute_error: 0.0283 - acc: 0.4294 - val_loss: 1.8649 - val_mean_absolute_error: 0.0267 - val_acc: 0.4660\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.96541 to 1.86495, saving model to weights.hdf5\n",
            "Epoch 6/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 1.8999 - mean_absolute_error: 0.0272 - acc: 0.4544 - val_loss: 1.8053 - val_mean_absolute_error: 0.0259 - val_acc: 0.4807\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.86495 to 1.80525, saving model to weights.hdf5\n",
            "Epoch 7/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 1.7987 - mean_absolute_error: 0.0262 - acc: 0.4818 - val_loss: 1.7350 - val_mean_absolute_error: 0.0253 - val_acc: 0.4978\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.80525 to 1.73502, saving model to weights.hdf5\n",
            "Epoch 8/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.7127 - mean_absolute_error: 0.0253 - acc: 0.5053 - val_loss: 1.6908 - val_mean_absolute_error: 0.0244 - val_acc: 0.5098\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.73502 to 1.69085, saving model to weights.hdf5\n",
            "Epoch 9/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.6313 - mean_absolute_error: 0.0245 - acc: 0.5246 - val_loss: 1.6415 - val_mean_absolute_error: 0.0238 - val_acc: 0.5281\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.69085 to 1.64147, saving model to weights.hdf5\n",
            "Epoch 10/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.5529 - mean_absolute_error: 0.0237 - acc: 0.5479 - val_loss: 1.6013 - val_mean_absolute_error: 0.0233 - val_acc: 0.5327\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.64147 to 1.60127, saving model to weights.hdf5\n",
            "Epoch 11/30\n",
            "72049/72049 [==============================] - 41s 567us/step - loss: 1.4805 - mean_absolute_error: 0.0229 - acc: 0.5647 - val_loss: 1.5661 - val_mean_absolute_error: 0.0226 - val_acc: 0.5488\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.60127 to 1.56608, saving model to weights.hdf5\n",
            "Epoch 12/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.4086 - mean_absolute_error: 0.0221 - acc: 0.5887 - val_loss: 1.5365 - val_mean_absolute_error: 0.0221 - val_acc: 0.5538\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.56608 to 1.53652, saving model to weights.hdf5\n",
            "Epoch 13/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 1.3387 - mean_absolute_error: 0.0213 - acc: 0.6069 - val_loss: 1.5068 - val_mean_absolute_error: 0.0217 - val_acc: 0.5646\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.53652 to 1.50675, saving model to weights.hdf5\n",
            "Epoch 14/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.2740 - mean_absolute_error: 0.0206 - acc: 0.6251 - val_loss: 1.4818 - val_mean_absolute_error: 0.0211 - val_acc: 0.5748\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.50675 to 1.48181, saving model to weights.hdf5\n",
            "Epoch 15/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.2100 - mean_absolute_error: 0.0198 - acc: 0.6430 - val_loss: 1.4833 - val_mean_absolute_error: 0.0206 - val_acc: 0.5778\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.48181\n",
            "Epoch 16/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 1.1514 - mean_absolute_error: 0.0191 - acc: 0.6596 - val_loss: 1.4532 - val_mean_absolute_error: 0.0202 - val_acc: 0.5878\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.48181 to 1.45318, saving model to weights.hdf5\n",
            "Epoch 17/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 1.0935 - mean_absolute_error: 0.0185 - acc: 0.6771 - val_loss: 1.4461 - val_mean_absolute_error: 0.0200 - val_acc: 0.5919\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.45318 to 1.44615, saving model to weights.hdf5\n",
            "Epoch 18/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 1.0454 - mean_absolute_error: 0.0179 - acc: 0.6898 - val_loss: 1.4290 - val_mean_absolute_error: 0.0196 - val_acc: 0.5973\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.44615 to 1.42903, saving model to weights.hdf5\n",
            "Epoch 19/30\n",
            "72049/72049 [==============================] - 41s 567us/step - loss: 0.9880 - mean_absolute_error: 0.0172 - acc: 0.7073 - val_loss: 1.4163 - val_mean_absolute_error: 0.0192 - val_acc: 0.6064\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.42903 to 1.41630, saving model to weights.hdf5\n",
            "Epoch 20/30\n",
            "72049/72049 [==============================] - 41s 568us/step - loss: 0.9414 - mean_absolute_error: 0.0166 - acc: 0.7218 - val_loss: 1.4158 - val_mean_absolute_error: 0.0189 - val_acc: 0.6065\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.41630 to 1.41583, saving model to weights.hdf5\n",
            "Epoch 21/30\n",
            "72049/72049 [==============================] - 41s 568us/step - loss: 0.8951 - mean_absolute_error: 0.0160 - acc: 0.7326 - val_loss: 1.4064 - val_mean_absolute_error: 0.0186 - val_acc: 0.6117\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.41583 to 1.40635, saving model to weights.hdf5\n",
            "Epoch 22/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 0.8476 - mean_absolute_error: 0.0153 - acc: 0.7485 - val_loss: 1.4110 - val_mean_absolute_error: 0.0185 - val_acc: 0.6138\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.40635\n",
            "Epoch 23/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 0.8111 - mean_absolute_error: 0.0149 - acc: 0.7581 - val_loss: 1.4040 - val_mean_absolute_error: 0.0181 - val_acc: 0.6183\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.40635 to 1.40404, saving model to weights.hdf5\n",
            "Epoch 24/30\n",
            "72049/72049 [==============================] - 41s 570us/step - loss: 0.7702 - mean_absolute_error: 0.0143 - acc: 0.7725 - val_loss: 1.4047 - val_mean_absolute_error: 0.0179 - val_acc: 0.6214\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.40404\n",
            "Epoch 25/30\n",
            "72049/72049 [==============================] - 41s 569us/step - loss: 0.7358 - mean_absolute_error: 0.0138 - acc: 0.7813 - val_loss: 1.4122 - val_mean_absolute_error: 0.0176 - val_acc: 0.6248\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.40404\n",
            "Epoch 26/30\n",
            "72049/72049 [==============================] - 41s 568us/step - loss: 0.6994 - mean_absolute_error: 0.0133 - acc: 0.7921 - val_loss: 1.4234 - val_mean_absolute_error: 0.0175 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.40404\n",
            "Epoch 00026: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UcTWSzsonp2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "40fdb4d6-b00f-4114-c084-7c42df96370c"
      },
      "cell_type": "code",
      "source": [
        "#plot learning history\n",
        "plot_history(history)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test accuracy: %.2f%%\" % (scores[2]*100))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa0f8421860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa0f82b9630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 61.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7yrN4CpWMG-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}